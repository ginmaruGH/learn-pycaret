{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Functions](https://pycaret.gitbook.io/docs/get-started/functions)\n",
    "\n",
    "## [Analyze（分析）](https://pycaret.gitbook.io/docs/get-started/functions/analyze)\n",
    "\n",
    "Analysis and model explainability functions in PyCaret\n",
    "\n",
    "PyCaretの解析・モデル説明可能関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot_model（プロットモデル）\n",
    "\n",
    "This function analyzes the performance of a trained model on the hold-out set. It may require re-training the model in certain cases.\n",
    "\n",
    "この関数は、ホールドアウト集合における学習済みモデルのパフォーマンスを分析します。場合によっては、モデルの再トレーニングが必要になるかもしれません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "lr = create_model('lr')\n",
    "\n",
    "# plot model\n",
    "plot_model(lr, plot='auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot_model](./images/plot_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the scale（スケールを変更する）\n",
    "\n",
    "The resolution scale of the figure can be changed with `scale` parameter.\n",
    "\n",
    "図の解像度スケールは `scale` パラメータで変更することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "lr = create_model('lr')\n",
    "\n",
    "# plot model\n",
    "plot_model(lr, plot='auc', scale=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot_model_scale](./images/plot_model_scale.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the plot（プロットを保存する）\n",
    "\n",
    "You can save the plot as a `png` file using the `save` parameter.\n",
    "\n",
    "プロットは `save` パラメータを使用して `png` ファイルとして保存することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "lr = create_model('lr')\n",
    "\n",
    "# plot model\n",
    "plot_model(lr, plot='auc', save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot_model_save](./images/plot_model_save.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customize the plot（プロットのカスタマイズ）\n",
    "\n",
    "PyCaret uses [Yellowbrick](https://www.scikit-yb.org/en/latest/) for most of the plotting work. Any argument that is acceptable for Yellowbrick visualizers can be passed as `plot_kwargs` parameter.\n",
    "\n",
    "PyCaret はプロット作業のほとんどに [Yellowbrick](https://www.scikit-yb.org/en/latest/) を使用しています。Yellowbrick のビジュアライザに受け入れられる任意の引数は `plot_kwargs` パラメータとして渡すことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "lr = create_model('lr')\n",
    "\n",
    "# plot model\n",
    "plot_model(lr, plot='confusion_matrix', plot_kwargs={'percent': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot_model_customize](./images/plot_model_customize.png)\n",
    "\n",
    "|||\n",
    "|:-:|:-:|\n",
    "|Before Customization|After Customization|\n",
    "|![before customization](./images/plot_model_before_customization.png)|![after customization](./images/plot_model_after_customization.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use train data（学習データの活用）\n",
    "\n",
    "If you want to assess the model plot on the train data, you can pass `use_train_data=True` in the `plot_model` function.\n",
    "\n",
    "もし、モデルのプロットを学習データで評価したい場合は、 `plot_model` 関数に `use_train_data=True` を渡すことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "lr = create_model('lr')\n",
    "\n",
    "# plot model\n",
    "plot_model(lr, plot='auc', use_train_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![plot_model_use_train_data](./images/plot_model_use_train_data.png)\n",
    "\n",
    "|||\n",
    "|:-:|:-:|\n",
    "|Train Data|Hold-out Data|\n",
    "|![plot_model_train_data](./images/plot_model_train_data.png)|![plot_model_hold-out_data](./images/plot_model_hold-out_data.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples by module（モジュール別の例）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification（分類）\n",
    "\n",
    "|Plot Name|Plot|\n",
    "|:-|:-|\n",
    "|Area Under the Curve（曲線下の面積）|‘auc’|\n",
    "|Confusion Matrix（混乱マトリクス）|‘confusion_matrix’|\n",
    "|Discrimination Threshold（判別しきい値）|‘threshold’|\n",
    "|Precision Recall Curve（精度リコール曲線）|‘pr’|\n",
    "|Class Prediction Error（クラス予測誤差）|‘error’|\n",
    "|Classification Report（分類レポート）|‘class_report’|\n",
    "|Recursive Feature Selection（再帰的特徴量選択）|‘rfe’|\n",
    "|Learning Curve（学習曲線）|‘learning’|\n",
    "|Validation Curve（検証曲線）|‘vc’|\n",
    "|Feature Importance（特徴量重要度）(Top 10)|‘feature’|\n",
    "|Feature Importance（特徴量重要度）(all)|'feature_all'|\n",
    "|Manifold Learning（多様な学習）|‘manifold’|\n",
    "|Calibration Curve（校正曲線）|‘calibration’|\n",
    "|Dimension Learning（次元学習）|‘dimension’|\n",
    "|Decision Boundary（決定境界）|‘boundary’|\n",
    "|Lift Curve（リフト曲線）|'lift'|\n",
    "|Gain Curve（利得曲線）|'gain'|\n",
    "|KS Statistic Plot（KS統計量プロット）|'ks'|\n",
    "|Model Hyperparameter（モデル ハイパーパラメータ）|‘parameter’|\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "|||\n",
    "|:-:|:-:|\n",
    "|auc|confusion_matrix|\n",
    "|![plot_model_auc](./images/plot_model_auc.png)|![plot_model_confusion_matrix](./images/plot_model_confusion_matrix.png)|\n",
    "|threshold|pr|\n",
    "|![plot_model_threshold](./images/plot_model_threshold.png)|![plot_model_pr](./images/plot_model_pr.png)|\n",
    "|error|class_report|\n",
    "|![plot_model_error](./images/plot_model_error.png)|![plot_model_class_report](./images/plot_model_class_report.png)|\n",
    "|rfe|learning|\n",
    "|![plot_model_rfe](./images/plot_model_rfe.png)|![plot_model_learning](./images/plot_model_learning.png)|\n",
    "|vc|feature|\n",
    "|![plot_model_vc](./images/plot_model_vc.png)|![plot_model_feature](./images/plot_model_feature.png)|\n",
    "|manifold|calibration|\n",
    "|![plot_model_manifold](./images/plot_model_manifold.png)|![plot_model_calibration](./images/plot_model_calibration.png)|\n",
    "|dimension|boundary|\n",
    "|![plot_model_dimension](./images/plot_model_dimension.png)|![plot_model_boundary](./images/plot_model_boundary.png)|\n",
    "|lift|gain|\n",
    "|![plot_model_lift](./images/plot_model_lift.png)|![plot_model_gain](./images/plot_model_gain.png)|\n",
    "|ks|parameter|\n",
    "|![plot_model_ks](./images/plot_model_ks.png)|![plot_model_parameter](./images/plot_model_parameter.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regression（回帰）\n",
    "\n",
    "|Name|Plot|\n",
    "|:-|:-|\n",
    "|Residuals Plot（残差プロット）|‘residuals’|\n",
    "|Prediction Error Plot（予測誤差プロット）|‘error’|\n",
    "|Cooks Distance Plot（クックス距離プロット）|‘cooks’|\n",
    "|Recursive Feature Selection（再帰的特徴量選択）|‘rfe’|\n",
    "|Feature Importance（特徴量重要度）(top 10)|‘feature’|\n",
    "|Learning Curve（学習曲線）|‘learning’|\n",
    "|Validation Curve（検証曲線）|‘vc’|\n",
    "|Manifold Learning（多様な学習）|‘manifold’|\n",
    "|Feature Importance（特徴量重要度）(all)|'feature_all'|\n",
    "|Model Hyperparameter（モデル ハイパーパラメータ）|‘parameter’|\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "|||\n",
    "|:-:|:-:|\n",
    "|residuals|error|\n",
    "|![plot_model_reg_residuals](./images/plot_model_reg_residuals.png)|![plot_model_reg_error](./images/plot_model_reg_error.png)|\n",
    "|cooks|rfe|\n",
    "|![plot_model_reg_cooks](./images/plot_model_reg_cooks.png)|![plot_model_reg_rfe](./images/plot_model_reg_rfe.png)|\n",
    "|feature|learning|\n",
    "|![plot_model_reg_feature](./images/plot_model_reg_feature.png)|![plot_model_reg_learning](./images/plot_model_reg_learning.png)|\n",
    "|vc|manifold|\n",
    "|![plot_model_reg_vc](./images/plot_model_reg_vc.png)|![plot_model_reg_manifold](./images/plot_model_reg_manifold.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clustering（クラスタリング）\n",
    "\n",
    "|Name|Plot|\n",
    "|:-|:-|\n",
    "|Cluster PCA Plot (2d)|‘cluster’|\n",
    "|Cluster TSnE (3d)|‘tsne’|\n",
    "|Elbow Plot（エルボープロット）|‘elbow’|\n",
    "|Silhouette Plot（シルエットプロット）|‘silhouette’|\n",
    "|Distance Plot（距離プロット）|‘distance’|\n",
    "|Distribution Plot（分布図）|‘distribution’|\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "|||\n",
    "|:-:|:-:|\n",
    "|cluster|tsne|\n",
    "|![plot_model_clu_cluster](./images/plot_model_clu_cluster.png)|![plot_model_clu_tsne](./images/plot_model_clu_tsne.png)|\n",
    "|elbow|silhouette|\n",
    "|![plot_model_clu_elbow](./images/plot_model_clu_elbow.png)|![plot_model_clu_silhouette](./images/plot_model_clu_silhouette.png)|\n",
    "|distance|distribution|\n",
    "|![plot_model_clu_distance](./images/plot_model_clu_distance.png)|![plot_model_clu_distribution](./images/plot_model_clu_distribution.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Anomaly Detection（異常検出）\n",
    "\n",
    "|Name|Plot|\n",
    "|:-|:-|\n",
    "|t-SNE (3d) Dimension Plot（t-SNE (3d) 次元プロット）|‘tsne’|\n",
    "|UMAP Dimensionality Plot（UMAP次元数プロット）|‘umap’|\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "|||\n",
    "|:-:|:-:|\n",
    "|tsne|umap|\n",
    "|![plot_model_ad_tsne](./images/plot_model_ad_tsne.png)|![plot_model_ad_umap](./images/plot_model_ad_umap.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Natural Language Processing（自然言語処理）\n",
    "\n",
    "|Name|Plot|\n",
    "|:-|:-|\n",
    "|Word Token Frequency（単語トークン頻度）|‘frequency’|\n",
    "|Word Distribution Plot（単語分布図）|‘distribution’|\n",
    "|Bigram Frequency Plot（バイグラム頻度プロット）|‘bigram’|\n",
    "|Trigram Frequency Plot（トライグラム頻度プロット）|‘trigram’|\n",
    "|Sentiment Polarity Plot（センチメント極座標プロット）|‘sentiment’|\n",
    "|Part of Speech Frequency（品詞の頻度）|‘pos’|\n",
    "|t-SNE (3d) Dimension Plot（t-SNE (3d) 次元プロット）|‘tsne’|\n",
    "|Topic Model (pyLDAvis)（トピックモデル(pyLDAvis)）|‘topic_model’|\n",
    "|Topic Infer Distribution（トピックの推定分布）|‘topic_distribution’|\n",
    "|Word cloud（ワードクラウド）|‘wordcloud’|\n",
    "|UMAP Dimensionality Plot（UMAP次元プロット）|‘umap’|\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "|||\n",
    "|:-:|:-:|\n",
    "|frequency|distribution|\n",
    "|![plot_model_nlp_frequency](./images/plot_model_nlp_frequency.png)|![plot_model_nlp_distribution](./images/plot_model_nlp_distribution.png)|\n",
    "|bigram|trigram|\n",
    "|![plot_model_nlp_bigram](./images/plot_model_nlp_bigram.png)|![plot_model_nlp_trigram](./images/plot_model_nlp_trigram.png)|\n",
    "|sentiment|pos|\n",
    "|![plot_model_nlp_sentiment](./images/plot_model_nlp_sentiment.png)|![plot_model_nlp_pos](./images/plot_model_nlp_pos.png)|\n",
    "|tsne|umap|\n",
    "|![plot_model_nlp_tsne](./images/plot_model_nlp_tsne.png)|![plot_model_nlp_umap](./images/plot_model_nlp_umap.png)|\n",
    "|wordcloud|topic_distribution|\n",
    "|![plot_model_nlp_wordcloud](./images/plot_model_nlp_wordcloud.png)|![plot_model_nlp_topic_distribution](./images/plot_model_nlp_topic_distribution.png)|\n",
    "|topic_model||\n",
    "|![plot_model_nlp_topic_model](./images/plot_model_nlp_topic_model.png)||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Association Rule Mining（アソシエーションルールマイニング）\n",
    "\n",
    "|||\n",
    "|:-:|:-:|\n",
    "|2d|3d|\n",
    "|![plot_model_arm_2d](./images/plot_model_arm_2d.png)|![plot_model_arm_3d](./images/plot_model_arm_3d.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate_model（評価モデル）\n",
    "\n",
    "The `evaluate_model` displays a user interface for analyzing the performance of a trained model. It calls the [plot_model](#plot_modelプロットモデル) function internally.\n",
    "\n",
    "`evaluate_model` は学習済みモデルのパフォーマンスを分析するためのユーザーインターフェースを表示します。内部で [plot_model] 関数を呼び出している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data=juice,  target='Purchase')\n",
    "\n",
    "# create model\n",
    "lr = create_model('lr')\n",
    "\n",
    "# launch evaluate widget\n",
    "evaluate_model(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![evaluate_model](./images/evaluate_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: This function only works in Jupyter Notebook or an equivalent environment.\n",
    ">\n",
    "> 注意：この関数は、Jupyter Notebookまたは同等の環境でのみ動作します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interpret_model（解釈モデル）\n",
    "\n",
    "This function analyzes the predictions generated from a trained model. Most plots in this function are implemented based on the SHAP (Shapley Additive exPlanations). For more info on this, please see <https://shap.readthedocs.io/en/latest/>\n",
    "\n",
    "この関数は，学習済みモデルから生成された予測値を解析します。この関数のほとんどのプロットは、SHAP (Shapley Additive exPlanations)に基づいて実装されています。これに関する詳細な情報は <https://shap.readthedocs.io/en/latest/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "xgboost = create_model('xgboost')\n",
    "\n",
    "# interpret model\n",
    "interpret_model(xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpret_model](./images/interpret_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the plot（プロットの保存）\n",
    "\n",
    "You can save the plot as a `png` file using the `save` parameter.\n",
    "\n",
    "プロットは `save` パラメータを使用して `png` ファイルとして保存することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "xgboost = create_model('xgboost')\n",
    "\n",
    "# interpret model\n",
    "interpret_model(xgboost, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE: When save=True no plot is displayed in the Notebook.\n",
    ">\n",
    "> 注：save=Trueの場合、ノートブックにプロットは表示されません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change plot type（プロットタイプの変更）\n",
    "\n",
    "There are a few different plot types available that can be changed by the `plot` parameter.\n",
    "\n",
    "プロットの種類はいくつかあり、 `plot` パラメータで変更することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation（相関）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "xgboost = create_model('xgboost')\n",
    "\n",
    "# interpret model\n",
    "interpret_model(xgboost, plot='correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpret_model](./images/interpret_model_correlation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, PyCaret uses the first feature in the dataset but that can be changed using `feature` parameter.\n",
    "\n",
    "デフォルトでは、PyCaret はデータセットの最初の特徴量を使用しますが、 `feature` パラメータを使用して変更することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "xgboost = create_model('xgboost')\n",
    "\n",
    "# interpret model\n",
    "interpret_model(xgboost, plot='correlation', feature='Age (years)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpret_model](./images/interpret_model_correlation_feature.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Partial Dependence Plot（部分依存プロット）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "xgboost = create_model('xgboost')\n",
    "\n",
    "# interpret model\n",
    "interpret_model(xgboost, plot='pdp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpret_model](./images/interpret_model_partial_dependence.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, PyCaret uses the first available feature in the dataset but this can be changed using the `feature` parameter.\n",
    "\n",
    "デフォルトでは、PyCaret はデータセット内の利用可能な最初の特徴量を使用しますが、これは `feature` パラメータを使用して変更することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "xgboost = create_model('xgboost')\n",
    "\n",
    "# interpret model\n",
    "interpret_model(xgboost, plot='pdp', feature='Age (years)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpret_model](./images/interpret_model_partial_dependence_feature.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Morris Sensitivity Analysis（モリス感応度分析）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "xgboost = create_model('xgboost')\n",
    "\n",
    "# interpret model\n",
    "interpret_model(xgboost, plot='msa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpret_model](./images/interpret_model_msa.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Permutation Feature Importance（並べ替え 特徴量 重要度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "xgboost = create_model('xgboost')\n",
    "\n",
    "# interpret model\n",
    "interpret_model(xgboost, plot='pfi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpret_model](./images/interpret_model_pfi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reason Plot（理由 プロット）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "xgboost = create_model('xgboost')\n",
    "\n",
    "# interpret model\n",
    "interpret_model(xgboost, plot='reason')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpret_model](./images/interpret_model_reason.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you generate `reason` plot without passing the specific index of test data, you will get the interactive plot displayed with the ability to select the x and y-axis. This will only be possible if you are using Jupyter Notebook or an equivalent environment. If you want to see this plot for a specific observation, you will have to pass the index in the `observation` parameter.\n",
    "\n",
    "テストデータの特定のインデックスを渡さずに `reason` プロットを生成すると、x軸とy軸を選択できるインタラクティブなプロットが表示されます。これはJupyter Notebookまたは同等の環境を使用している場合のみ可能です。もし、特定の観測データに対してこのプロットを見たい場合は、`observation`パラメータにそのインデックスを渡す必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "xgboost = create_model('xgboost')\n",
    "\n",
    "# interpret model\n",
    "interpret_model(xgboost, plot='reason', observation=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpret_model](./images/interpret_model_reason_observation.png)\n",
    "\n",
    "Here the `observation = 1` means index 1 from the test set.\n",
    "\n",
    "ここで、`observation = 1`は、テストセットからのインデックス1を意味します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use train data（学習データを利用する）\n",
    "\n",
    "By default, all the plots are generated on the test dataset. If you want to generate plots using a train data set (not recommended) you can use `use_train_data` parameter.\n",
    "\n",
    "デフォルトでは、すべてのプロットはテストデータセットで生成されます。もし、トレーニングデータセットを用いてプロットを生成したい場合（推奨しません）、`use_train_data`パラメータを使用することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# creating a model\n",
    "xgboost = create_model('xgboost')\n",
    "\n",
    "# interpret model\n",
    "interpret_model(xgboost, use_train_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![interpret_model](./images/interpret_model_use_train_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dashboard（ダッシュボード）\n",
    "\n",
    "The `dashboard` function generates the interactive dashboard for a trained model. The dashboard is implemented using ExplainerDashboard ([explainerdashboard.readthedocs.io](https://explainerdashboard.readthedocs.io/en/latest/))\n",
    "\n",
    "`dashboard` 関数は、学習済みモデルのインタラクティブなダッシュボードを生成します。ダッシュボードは ExplainerDashboard を使って実装されています。([explainerdashboard.readthedocs.io](https://explainerdashboard.readthedocs.io/en/latest/))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dashboard Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data=juice,  target='Purchase')\n",
    "\n",
    "# train model\n",
    "lr = create_model('lr')\n",
    "\n",
    "# launch dashboard\n",
    "dashboard(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dashboard](./images/dashboard1.png)\n",
    "\n",
    "![dashboard](./images/dashboard2.png)\n",
    "\n",
    "![dashboard](./images/dashboard3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video:\n",
    "\n",
    "<https://www.youtube.com/watch?v=FZ5-GtdYez0>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deep_check（ディープチェック）\n",
    "\n",
    "This function runs a full suite check over a trained model using the [deepchecks](https://github.com/deepchecks/deepchecks) library.\n",
    "\n",
    "この関数は、[deepchecks](https://github.com/deepchecks/deepchecks) ライブラリを使って、学習済みモデルに対する完全なスイートチェックを実行します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Check Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data=juice,  target='Purchase')\n",
    "\n",
    "# train model\n",
    "lr = create_model('lr')\n",
    "\n",
    "# deep check model\n",
    "deep_check(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![deep_check](./images/deep_check.png)\n",
    "\n",
    "![deep_check](./images/deep_check2.png)\n",
    "\n",
    "![deep_check](./images/deep_check3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This function is in experimental mode. deepchecks require scikit-learn>1.0 version, whereas pycaret requires scikit-learn==0.23.2. Hence after installing deepchecks you must uninstall scikit-learn and reinstall scikit-learn==0.23.2 otherwise you will get an error with pycaret. The future version of pycaret will be scikit-learn>1.0 compatible.\n",
    "\n",
    "deepchecks は scikit-learn>1.0 バージョンを必要とし、一方 pycaret は scikit-learn==0.23.2 を必要とします。したがって、deepchecksをインストールした後、scikit-learnをアンインストールし、scikit-learn=0.23.2を再インストールしなければ、pycaretでエラーが発生します。将来のpycaretのバージョンはscikit-learn>1.0と互換性がある予定です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eda\n",
    "\n",
    "This function generates automated Exploratory Data Analysis (EDA) using the AutoViz library. You must install Autoviz separately `pip install autoviz` to use this function.\n",
    "\n",
    "この関数は、AutoVizライブラリを用いて探索的データ解析（EDA）を自動生成するものです。この関数を使用するには、別途 `pip install autoviz` でAutovizをインストールする必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data=juice,  target='Purchase')\n",
    "\n",
    "# launch eda\n",
    "eda(display_format='bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eda](./images/eda.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also run this function with `display_format = 'svg'`.\n",
    "\n",
    "また、この関数は `display_format = 'svg'` と指定して実行することもできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "juice = get_data('juice')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data=juice,  target='Purchase')\n",
    "\n",
    "# launch eda\n",
    "eda(display_format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ead2](./images/eda2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video:\n",
    "\n",
    "<https://www.youtube.com/watch?v=Pm5VOuYqU4Q>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check_fairness（公平性の確認）\n",
    "\n",
    "There are many approaches to conceptualizing fairness. The `check_fairness` function follows the approach known as group fairness, which asks: which groups of individuals are at risk for experiencing harm. `check_fairness` provides fairness-related metrics between different groups (also called sub-population).\n",
    "\n",
    "公平性を概念化するアプローチには多くのものがあります。`check_fairness`関数は、グループ・フェアネスとして知られるアプローチに従っています。これは、「どのグループの個体が損害を経験するリスクがあるか」を問うものです。`check_fairness` は異なるグループ（サブ集団とも呼ばれる）間の公平性に関連するメトリクスを提供します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Fairness Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "income = get_data('income')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "exp_name = setup(data=income,  target='income >50K')\n",
    "\n",
    "# train model\n",
    "lr = create_model('lr')\n",
    "\n",
    "# check model fairness\n",
    "lr_fairness = check_fairness(lr, sensitive_features=['sex', 'race'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![check_fairness](./images/check_fairness1.png)\n",
    "\n",
    "![check_fairness](./images/check_fairness2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video:\n",
    "\n",
    "<https://www.youtube.com/watch?v=mjhDKuLRpM0>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_leaderboard（リーダーボードの取得）\n",
    "\n",
    "This function returns the leaderboard of all models trained in the current setup.\n",
    "\n",
    "この関数は、現在の設定で学習させた全モデルのリーダーボードを返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "diabetes = get_data('diabetes')\n",
    "\n",
    "# init setup\n",
    "from pycaret.classification import *\n",
    "clf1 = setup(data=diabetes, target='Class variable')\n",
    "\n",
    "# compare models\n",
    "top3 = compare_models(n_select=3)\n",
    "\n",
    "# tune top 3 models\n",
    "tuned_top3 = [tune_model(i) for i in top3]\n",
    "\n",
    "# ensemble top 3 tuned models\n",
    "ensembled_top3 = [ensemble_model(i) for i in tuned_top3]\n",
    "\n",
    "# blender\n",
    "blender = blend_models(tuned_top3)\n",
    "\n",
    "# stacker\n",
    "stacker = stack_models(tuned_top3)\n",
    "\n",
    "# check leaderboard\n",
    "get_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![get_leaderboard](./images/get_leaderboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also access the trained Pipeline with this.\n",
    "\n",
    "また、これを使って訓練されたパイプラインにアクセスすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check leaderboard\n",
    "lb = get_leaderboard()\n",
    "\n",
    "# select top model\n",
    "lb.iloc[0]['Model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![get_leaderboard](./images/get_leaderboard2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### assign_model（代入モデル）\n",
    "\n",
    "This function assigns labels to the training dataset using the trained model. It is available for [Clustering](https://pycaret.gitbook.io/docs/get-started/modules), [Anomaly Detection](https://pycaret.gitbook.io/docs/get-started/modules), and [NLP](https://pycaret.gitbook.io/docs/get-started/modules) modules.\n",
    "\n",
    "学習済みモデルを用いて、学習データセットにラベルを付与する関数です。[クラスタリング](https://pycaret.gitbook.io/docs/get-started/modules)、[異常検知](https://pycaret.gitbook.io/docs/get-started/modules)および[自然言語処理](https://pycaret.gitbook.io/docs/get-started/modules)の各モジュールで利用可能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "jewellery = get_data('jewellery')\n",
    "\n",
    "# init setup\n",
    "from pycaret.clustering import *\n",
    "clu1 = setup(data=jewellery)\n",
    "\n",
    "# train a model\n",
    "kmeans = create_model('kmeans')\n",
    "\n",
    "# assign model\n",
    "assign_model(kmeans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![assign_model](./images/assign_model_clustering.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "anomaly = get_data('anomaly')\n",
    "\n",
    "# init setup\n",
    "from pycaret.anomaly import *\n",
    "ano1 = setup(data=anomaly)\n",
    "\n",
    "# train a model\n",
    "iforest = create_model('iforest')\n",
    "\n",
    "# assign model\n",
    "assign_model(iforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![assign_model_anomaly_detection](./images/assign_model_anomaly_detection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "from pycaret.datasets import get_data\n",
    "kiva = get_data('kiva')\n",
    "\n",
    "# init setup\n",
    "from pycaret.nlp import *\n",
    "nlp1 = setup(data=kiva, target='en')\n",
    "\n",
    "# train a model\n",
    "lda = create_model('lda')\n",
    "\n",
    "# assign model\n",
    "assign_model(lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![assign_model](./images/assign_model_nlp.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "144d929da0570c40592d9dc325047f87d05d6a3c34760fe6027613ddef8a9521"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
